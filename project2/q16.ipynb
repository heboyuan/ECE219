{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# libraries, helper functions and constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are all the libraries that we used for question 16 and some untility functions such as get_cluster_metrics which output the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from umap import UMAP\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from hdbscan import HDBSCAN\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics.cluster import (\n",
    "    contingency_matrix,\n",
    "    homogeneity_score,\n",
    "    v_measure_score,\n",
    "    completeness_score,\n",
    "    adjusted_rand_score,\n",
    "    adjusted_mutual_info_score\n",
    ")\n",
    "from plotmat import plot_mat\n",
    "\n",
    "def get_cluster_metrics(y_true, y_pred, metrics=None):\n",
    "    if not metrics:\n",
    "        metrics = [\n",
    "            homogeneity_score,\n",
    "            completeness_score,\n",
    "            v_measure_score,\n",
    "            adjusted_rand_score,\n",
    "            adjusted_mutual_info_score\n",
    "        ]\n",
    "    d = {}\n",
    "    for m in metrics:\n",
    "        d[m.__name__] = m(y_true, y_pred)\n",
    "    df = pd.DataFrame(d, index=[0]).T\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'metric', 0: 'score'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load in data and transform to TF-IDF vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data into a pandas dataframe from csv file, and uses factorize function to assign unique ID to each category. category_id_df dataframe holds category name and corresponding ID, and labels dataframe holds the label corresponding to training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./BBC_News_Train.csv\")\n",
    "df['category_id'], _ = df['Category'].factorize()\n",
    "category_id_df = df[['Category', 'category_id']].drop_duplicates()\n",
    "labels = df.category_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we uses Term Frequency-Inverse Document Frequency (TF-IDF) metric to build representation vectors for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df=5, stop_words='english')\n",
    "tfidf_data = tfidf.fit_transform(df.Text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dimension reduction (Truncated SVD, NMF and UMAP with K-mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluated three different dimension reduction method (Truncated SVD, NMF and UMAP) with components number ranging from 1 to 800. We evaluate the effectiveness of the dimension reduction using K-mean and clustering algorithm. The performance resulting from each dimension reduction data are shown in tables below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(\n",
    "    n_clusters=category_id_df.Category.count(),\n",
    "    random_state=0,\n",
    "    max_iter=5000,\n",
    "    n_init=50\n",
    ")\n",
    "\n",
    "n_components = [1, 2, 3, 5, 10, 20, 50, 100, 300, 500, 800, 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>homogeneity_score</th>\n",
       "      <th>completeness_score</th>\n",
       "      <th>v_measure_score</th>\n",
       "      <th>adjusted_rand_score</th>\n",
       "      <th>adjusted_mutual_info_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.094331</td>\n",
       "      <td>0.104362</td>\n",
       "      <td>0.099094</td>\n",
       "      <td>0.049817</td>\n",
       "      <td>0.095885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.303752</td>\n",
       "      <td>0.346610</td>\n",
       "      <td>0.323769</td>\n",
       "      <td>0.193236</td>\n",
       "      <td>0.321323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.448852</td>\n",
       "      <td>0.502422</td>\n",
       "      <td>0.474129</td>\n",
       "      <td>0.355048</td>\n",
       "      <td>0.472247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.636503</td>\n",
       "      <td>0.685090</td>\n",
       "      <td>0.659903</td>\n",
       "      <td>0.572929</td>\n",
       "      <td>0.658711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.633928</td>\n",
       "      <td>0.707318</td>\n",
       "      <td>0.668616</td>\n",
       "      <td>0.543747</td>\n",
       "      <td>0.667433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.616071</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.652664</td>\n",
       "      <td>0.514318</td>\n",
       "      <td>0.651419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.635522</td>\n",
       "      <td>0.718284</td>\n",
       "      <td>0.674373</td>\n",
       "      <td>0.536805</td>\n",
       "      <td>0.673204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.620452</td>\n",
       "      <td>0.698453</td>\n",
       "      <td>0.657146</td>\n",
       "      <td>0.517965</td>\n",
       "      <td>0.655918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.715419</td>\n",
       "      <td>0.757440</td>\n",
       "      <td>0.735830</td>\n",
       "      <td>0.662944</td>\n",
       "      <td>0.734912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.782276</td>\n",
       "      <td>0.799019</td>\n",
       "      <td>0.790559</td>\n",
       "      <td>0.780867</td>\n",
       "      <td>0.789844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.721031</td>\n",
       "      <td>0.756067</td>\n",
       "      <td>0.738133</td>\n",
       "      <td>0.689256</td>\n",
       "      <td>0.737227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.632077</td>\n",
       "      <td>0.710491</td>\n",
       "      <td>0.668994</td>\n",
       "      <td>0.532924</td>\n",
       "      <td>0.667809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      homogeneity_score  completeness_score  v_measure_score  \\\n",
       "1              0.094331            0.104362         0.099094   \n",
       "2              0.303752            0.346610         0.323769   \n",
       "3              0.448852            0.502422         0.474129   \n",
       "5              0.636503            0.685090         0.659903   \n",
       "10             0.633928            0.707318         0.668616   \n",
       "20             0.616071            0.693878         0.652664   \n",
       "50             0.635522            0.718284         0.674373   \n",
       "100            0.620452            0.698453         0.657146   \n",
       "300            0.715419            0.757440         0.735830   \n",
       "500            0.782276            0.799019         0.790559   \n",
       "800            0.721031            0.756067         0.738133   \n",
       "1000           0.632077            0.710491         0.668994   \n",
       "\n",
       "      adjusted_rand_score  adjusted_mutual_info_score  \n",
       "1                0.049817                    0.095885  \n",
       "2                0.193236                    0.321323  \n",
       "3                0.355048                    0.472247  \n",
       "5                0.572929                    0.658711  \n",
       "10               0.543747                    0.667433  \n",
       "20               0.514318                    0.651419  \n",
       "50               0.536805                    0.673204  \n",
       "100              0.517965                    0.655918  \n",
       "300              0.662944                    0.734912  \n",
       "500              0.780867                    0.789844  \n",
       "800              0.689256                    0.737227  \n",
       "1000             0.532924                    0.667809  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for r in n_components:\n",
    "    input_svd = TruncatedSVD(\n",
    "        n_components=r, random_state=RANDOM_SEED).fit_transform(tfidf_data)\n",
    "    preds = km.fit_predict(input_svd)\n",
    "    scores.append(get_cluster_metrics(labels, preds)['score'].tolist())\n",
    "metrics = get_cluster_metrics(labels, preds)['metric'].tolist()\n",
    "svd_metrics_df = pd.DataFrame(scores, columns=metrics, index=n_components)\n",
    "svd_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boyuan/.local/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1090: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n",
      "/home/boyuan/.local/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1090: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n",
      "/home/boyuan/.local/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1090: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>homogeneity_score</th>\n",
       "      <th>completeness_score</th>\n",
       "      <th>v_measure_score</th>\n",
       "      <th>adjusted_rand_score</th>\n",
       "      <th>adjusted_mutual_info_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.094331</td>\n",
       "      <td>0.104362</td>\n",
       "      <td>0.099094</td>\n",
       "      <td>0.049817</td>\n",
       "      <td>0.095885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.247705</td>\n",
       "      <td>0.308859</td>\n",
       "      <td>0.274922</td>\n",
       "      <td>0.127401</td>\n",
       "      <td>0.272187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.477529</td>\n",
       "      <td>0.493823</td>\n",
       "      <td>0.485539</td>\n",
       "      <td>0.343355</td>\n",
       "      <td>0.483772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.663295</td>\n",
       "      <td>0.708868</td>\n",
       "      <td>0.685325</td>\n",
       "      <td>0.612784</td>\n",
       "      <td>0.684226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.472978</td>\n",
       "      <td>0.627064</td>\n",
       "      <td>0.539229</td>\n",
       "      <td>0.319264</td>\n",
       "      <td>0.537447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.254254</td>\n",
       "      <td>0.456657</td>\n",
       "      <td>0.326642</td>\n",
       "      <td>0.074724</td>\n",
       "      <td>0.323695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.143036</td>\n",
       "      <td>0.427838</td>\n",
       "      <td>0.214395</td>\n",
       "      <td>0.049344</td>\n",
       "      <td>0.210228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.068191</td>\n",
       "      <td>0.370604</td>\n",
       "      <td>0.115188</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>0.109439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.084514</td>\n",
       "      <td>0.349946</td>\n",
       "      <td>0.136147</td>\n",
       "      <td>0.015954</td>\n",
       "      <td>0.131116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.032743</td>\n",
       "      <td>0.290324</td>\n",
       "      <td>0.058849</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>0.052556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.012738</td>\n",
       "      <td>0.241210</td>\n",
       "      <td>0.024199</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.016873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.006937</td>\n",
       "      <td>0.210721</td>\n",
       "      <td>0.013432</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.006606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      homogeneity_score  completeness_score  v_measure_score  \\\n",
       "1              0.094331            0.104362         0.099094   \n",
       "2              0.247705            0.308859         0.274922   \n",
       "3              0.477529            0.493823         0.485539   \n",
       "5              0.663295            0.708868         0.685325   \n",
       "10             0.472978            0.627064         0.539229   \n",
       "20             0.254254            0.456657         0.326642   \n",
       "50             0.143036            0.427838         0.214395   \n",
       "100            0.068191            0.370604         0.115188   \n",
       "300            0.084514            0.349946         0.136147   \n",
       "500            0.032743            0.290324         0.058849   \n",
       "800            0.012738            0.241210         0.024199   \n",
       "1000           0.006937            0.210721         0.013432   \n",
       "\n",
       "      adjusted_rand_score  adjusted_mutual_info_score  \n",
       "1                0.049817                    0.095885  \n",
       "2                0.127401                    0.272187  \n",
       "3                0.343355                    0.483772  \n",
       "5                0.612784                    0.684226  \n",
       "10               0.319264                    0.537447  \n",
       "20               0.074724                    0.323695  \n",
       "50               0.049344                    0.210228  \n",
       "100              0.011561                    0.109439  \n",
       "300              0.015954                    0.131116  \n",
       "500              0.005426                    0.052556  \n",
       "800              0.001587                    0.016873  \n",
       "1000             0.000603                    0.006606  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for r in n_components:\n",
    "    inputs_nmf = NMF(n_components=r, init='random',\n",
    "                     random_state=RANDOM_SEED).fit_transform(tfidf_data)\n",
    "    preds = km.fit_predict(inputs_nmf)\n",
    "    scores.append(get_cluster_metrics(labels, preds)['score'].tolist())\n",
    "metrics = get_cluster_metrics(labels, preds)['metric'].tolist()\n",
    "nmf_metrics_df = pd.DataFrame(scores, columns=metrics, index=n_components)\n",
    "nmf_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For UMAP, we tested on both Eucledian and Cosine distance, and the result are shown below "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>homogeneity_score</th>\n",
       "      <th>completeness_score</th>\n",
       "      <th>v_measure_score</th>\n",
       "      <th>adjusted_rand_score</th>\n",
       "      <th>adjusted_mutual_info_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.648914</td>\n",
       "      <td>0.652242</td>\n",
       "      <td>0.650574</td>\n",
       "      <td>0.682402</td>\n",
       "      <td>0.649391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.774596</td>\n",
       "      <td>0.774988</td>\n",
       "      <td>0.774792</td>\n",
       "      <td>0.807148</td>\n",
       "      <td>0.774031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.772620</td>\n",
       "      <td>0.773033</td>\n",
       "      <td>0.772827</td>\n",
       "      <td>0.806810</td>\n",
       "      <td>0.772059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.774802</td>\n",
       "      <td>0.775294</td>\n",
       "      <td>0.775048</td>\n",
       "      <td>0.809163</td>\n",
       "      <td>0.774288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.768688</td>\n",
       "      <td>0.769228</td>\n",
       "      <td>0.768958</td>\n",
       "      <td>0.801502</td>\n",
       "      <td>0.768178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.764969</td>\n",
       "      <td>0.765726</td>\n",
       "      <td>0.765348</td>\n",
       "      <td>0.797540</td>\n",
       "      <td>0.764555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.761241</td>\n",
       "      <td>0.762329</td>\n",
       "      <td>0.761785</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.760980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.767745</td>\n",
       "      <td>0.768666</td>\n",
       "      <td>0.768206</td>\n",
       "      <td>0.800770</td>\n",
       "      <td>0.767422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.763184</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>0.763667</td>\n",
       "      <td>0.798226</td>\n",
       "      <td>0.762869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.765523</td>\n",
       "      <td>0.766331</td>\n",
       "      <td>0.765927</td>\n",
       "      <td>0.800668</td>\n",
       "      <td>0.765136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.765306</td>\n",
       "      <td>0.766059</td>\n",
       "      <td>0.765683</td>\n",
       "      <td>0.797566</td>\n",
       "      <td>0.764891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.768891</td>\n",
       "      <td>0.769484</td>\n",
       "      <td>0.769187</td>\n",
       "      <td>0.802630</td>\n",
       "      <td>0.768408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      homogeneity_score  completeness_score  v_measure_score  \\\n",
       "1              0.648914            0.652242         0.650574   \n",
       "2              0.774596            0.774988         0.774792   \n",
       "3              0.772620            0.773033         0.772827   \n",
       "5              0.774802            0.775294         0.775048   \n",
       "10             0.768688            0.769228         0.768958   \n",
       "20             0.764969            0.765726         0.765348   \n",
       "50             0.761241            0.762329         0.761785   \n",
       "100            0.767745            0.768666         0.768206   \n",
       "300            0.763184            0.764151         0.763667   \n",
       "500            0.765523            0.766331         0.765927   \n",
       "800            0.765306            0.766059         0.765683   \n",
       "1000           0.768891            0.769484         0.769187   \n",
       "\n",
       "      adjusted_rand_score  adjusted_mutual_info_score  \n",
       "1                0.682402                    0.649391  \n",
       "2                0.807148                    0.774031  \n",
       "3                0.806810                    0.772059  \n",
       "5                0.809163                    0.774288  \n",
       "10               0.801502                    0.768178  \n",
       "20               0.797540                    0.764555  \n",
       "50               0.795600                    0.760980  \n",
       "100              0.800770                    0.767422  \n",
       "300              0.798226                    0.762869  \n",
       "500              0.800668                    0.765136  \n",
       "800              0.797566                    0.764891  \n",
       "1000             0.802630                    0.768408  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for n in n_components:\n",
    "    umapfit = UMAP(n_components = n, metric = 'euclidean')\n",
    "    inputs_umap = umapfit.fit_transform(tfidf_data)\n",
    "    preds = km.fit_predict(inputs_umap)\n",
    "    get_cluster_metrics(labels, preds)\n",
    "    scores.append(get_cluster_metrics(labels, preds)['score'].tolist())\n",
    "metrics = get_cluster_metrics(labels, preds)['metric'].tolist()\n",
    "metrics_df = pd.DataFrame(scores, columns=metrics, index=n_components)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>homogeneity_score</th>\n",
       "      <th>completeness_score</th>\n",
       "      <th>v_measure_score</th>\n",
       "      <th>adjusted_rand_score</th>\n",
       "      <th>adjusted_mutual_info_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.684861</td>\n",
       "      <td>0.683499</td>\n",
       "      <td>0.684179</td>\n",
       "      <td>0.693706</td>\n",
       "      <td>0.683114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.697573</td>\n",
       "      <td>0.695054</td>\n",
       "      <td>0.696311</td>\n",
       "      <td>0.702069</td>\n",
       "      <td>0.695288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.760475</td>\n",
       "      <td>0.762211</td>\n",
       "      <td>0.761342</td>\n",
       "      <td>0.794154</td>\n",
       "      <td>0.760535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.763035</td>\n",
       "      <td>0.763932</td>\n",
       "      <td>0.763483</td>\n",
       "      <td>0.797935</td>\n",
       "      <td>0.762684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.766929</td>\n",
       "      <td>0.767975</td>\n",
       "      <td>0.767451</td>\n",
       "      <td>0.802639</td>\n",
       "      <td>0.766666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.757243</td>\n",
       "      <td>0.758450</td>\n",
       "      <td>0.757846</td>\n",
       "      <td>0.791636</td>\n",
       "      <td>0.757028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.759846</td>\n",
       "      <td>0.760991</td>\n",
       "      <td>0.760418</td>\n",
       "      <td>0.794313</td>\n",
       "      <td>0.759609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.763592</td>\n",
       "      <td>0.764522</td>\n",
       "      <td>0.764057</td>\n",
       "      <td>0.799254</td>\n",
       "      <td>0.763260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.764780</td>\n",
       "      <td>0.765805</td>\n",
       "      <td>0.765292</td>\n",
       "      <td>0.799528</td>\n",
       "      <td>0.764499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.770041</td>\n",
       "      <td>0.770846</td>\n",
       "      <td>0.770443</td>\n",
       "      <td>0.804797</td>\n",
       "      <td>0.769668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.756697</td>\n",
       "      <td>0.757925</td>\n",
       "      <td>0.757311</td>\n",
       "      <td>0.790345</td>\n",
       "      <td>0.756490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.766731</td>\n",
       "      <td>0.767452</td>\n",
       "      <td>0.767091</td>\n",
       "      <td>0.804319</td>\n",
       "      <td>0.766305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      homogeneity_score  completeness_score  v_measure_score  \\\n",
       "1              0.684861            0.683499         0.684179   \n",
       "2              0.697573            0.695054         0.696311   \n",
       "3              0.760475            0.762211         0.761342   \n",
       "5              0.763035            0.763932         0.763483   \n",
       "10             0.766929            0.767975         0.767451   \n",
       "20             0.757243            0.758450         0.757846   \n",
       "50             0.759846            0.760991         0.760418   \n",
       "100            0.763592            0.764522         0.764057   \n",
       "300            0.764780            0.765805         0.765292   \n",
       "500            0.770041            0.770846         0.770443   \n",
       "800            0.756697            0.757925         0.757311   \n",
       "1000           0.766731            0.767452         0.767091   \n",
       "\n",
       "      adjusted_rand_score  adjusted_mutual_info_score  \n",
       "1                0.693706                    0.683114  \n",
       "2                0.702069                    0.695288  \n",
       "3                0.794154                    0.760535  \n",
       "5                0.797935                    0.762684  \n",
       "10               0.802639                    0.766666  \n",
       "20               0.791636                    0.757028  \n",
       "50               0.794313                    0.759609  \n",
       "100              0.799254                    0.763260  \n",
       "300              0.799528                    0.764499  \n",
       "500              0.804797                    0.769668  \n",
       "800              0.790345                    0.756490  \n",
       "1000             0.804319                    0.766305  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for n in n_components:\n",
    "    umapfit = UMAP(n_components = n, metric = 'cosine')\n",
    "    inputs_umap = umapfit.fit_transform(tfidf_data)\n",
    "    preds = km.fit_predict(inputs_umap)\n",
    "    get_cluster_metrics(labels, preds)\n",
    "    scores.append(get_cluster_metrics(labels, preds)['score'].tolist())\n",
    "metrics = get_cluster_metrics(labels, preds)['metric'].tolist()\n",
    "metrics_df = pd.DataFrame(scores, columns=metrics, index=n_components)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, Truncated SVD achieves the best score of 0.78 to 0.80 in all scoring categories; UMAP score is very close to that of Truncated SVD, and even surpass it in adjusted Rand score; NMF perform the worst, which might be caused by the non-negative weighing constrain making it fail to capture matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clustering (K-mean, Agglomerative, DBSCAN, HDBSCAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use TruncatedSVD with 500 component for K-mean and cosine distance UMAP with 1000 component for Agglomerative, DBSCAN and HDBSCAN (these three work well with UMAP data). The results are shown in the tables below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "svd_train = TruncatedSVD(\n",
    "    n_components=500, random_state=RANDOM_SEED).fit_transform(tfidf_data)\n",
    "\n",
    "umap_train = UMAP(\n",
    "    n_components = 1000, metric = 'cosine').fit_transform(tfidf_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>homogeneity_score</td>\n",
       "      <td>0.782276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>completeness_score</td>\n",
       "      <td>0.799019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v_measure_score</td>\n",
       "      <td>0.790559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adjusted_rand_score</td>\n",
       "      <td>0.780867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adjusted_mutual_info_score</td>\n",
       "      <td>0.789844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       metric     score\n",
       "0           homogeneity_score  0.782276\n",
       "1          completeness_score  0.799019\n",
       "2             v_measure_score  0.790559\n",
       "3         adjusted_rand_score  0.780867\n",
       "4  adjusted_mutual_info_score  0.789844"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = km.fit_predict(svd_train)\n",
    "\n",
    "get_cluster_metrics(labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agglomerative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>homogeneity_score</td>\n",
       "      <td>0.775997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>completeness_score</td>\n",
       "      <td>0.776436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v_measure_score</td>\n",
       "      <td>0.776217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adjusted_rand_score</td>\n",
       "      <td>0.813692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adjusted_mutual_info_score</td>\n",
       "      <td>0.775461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       metric     score\n",
       "0           homogeneity_score  0.775997\n",
       "1          completeness_score  0.776436\n",
       "2             v_measure_score  0.776217\n",
       "3         adjusted_rand_score  0.813692\n",
       "4  adjusted_mutual_info_score  0.775461"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = AgglomerativeClustering(n_clusters = category_id_df.Category.count(), linkage = 'ward').fit_predict(umap_train)\n",
    "\n",
    "get_cluster_metrics(labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For DBSCAN, we tested Epsilon ranging from 1 to 21 and min sample ranging from 5 to 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_list = [x * 0.05 for x in range(1, 21)]\n",
    "min_samples_list = list(range(5,200,10))\n",
    "\n",
    "scores = []\n",
    "for ep in eps_list:\n",
    "    for min_samp in min_samples_list:\n",
    "        preds = DBSCAN(eps = ep, min_samples = min_samp, n_jobs = -1).fit_predict(umap_train)\n",
    "        row = get_cluster_metrics(labels, preds)['score'].tolist()\n",
    "        row.append(ep)\n",
    "        row.append(min_samp)\n",
    "        scores.append(row)\n",
    "        \n",
    "titles = get_cluster_metrics(labels, preds)['metric'].tolist()\n",
    "titles.append(\"Epsilon\")\n",
    "titles.append(\"min_samples\")\n",
    "metrics_df = pd.DataFrame(scores, columns=titles)\n",
    "metrics_df.to_excel('DBSCAN.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed result can be found in DBSCAN.xlsx, here I picked the one with highest score and show it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>homogeneity_score</td>\n",
       "      <td>0.722026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>completeness_score</td>\n",
       "      <td>0.647094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v_measure_score</td>\n",
       "      <td>0.682510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adjusted_rand_score</td>\n",
       "      <td>0.669950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adjusted_mutual_info_score</td>\n",
       "      <td>0.681241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       metric     score\n",
       "0           homogeneity_score  0.722026\n",
       "1          completeness_score  0.647094\n",
       "2             v_measure_score  0.682510\n",
       "3         adjusted_rand_score  0.669950\n",
       "4  adjusted_mutual_info_score  0.681241"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = DBSCAN(eps = 0.95, min_samples = 75, n_jobs = -1).fit_predict(umap_train)\n",
    "\n",
    "get_cluster_metrics(labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For HDBSCAN, we set min cluster size to 100 and tested min cluster size ranging from 1 to 21 and min sample ranging from 5 to 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_eps_list = [x * 0.05 for x in range(1, 21)]\n",
    "min_samples_list = list(range(5,500,10))\n",
    "\n",
    "scores = []\n",
    "for ep in clust_eps_list:\n",
    "    for min_samp in min_samples_list:\n",
    "        preds = HDBSCAN(min_cluster_size=100, min_samples = min_samp, cluster_selection_epsilon = ep, core_dist_n_jobs=-1).fit_predict(umap_train)\n",
    "        row = get_cluster_metrics(labels, preds)['score'].tolist()\n",
    "        row.append(ep)\n",
    "        row.append(min_samp)\n",
    "        scores.append(row)\n",
    "        \n",
    "titles = get_cluster_metrics(labels, preds)['metric'].tolist()\n",
    "titles.append(\"Cluster_sel_Epsilon\")\n",
    "titles.append(\"min_samples\")\n",
    "metrics_df = pd.DataFrame(scores, columns=titles)\n",
    "metrics_df.to_excel('HDBSCAN.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed result can be found in HDBSCAN.xlsx, here I picked the one with highest score and show it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>homogeneity_score</td>\n",
       "      <td>0.554131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>completeness_score</td>\n",
       "      <td>0.773971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v_measure_score</td>\n",
       "      <td>0.645856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adjusted_rand_score</td>\n",
       "      <td>0.565880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adjusted_mutual_info_score</td>\n",
       "      <td>0.644796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       metric     score\n",
       "0           homogeneity_score  0.554131\n",
       "1          completeness_score  0.773971\n",
       "2             v_measure_score  0.645856\n",
       "3         adjusted_rand_score  0.565880\n",
       "4  adjusted_mutual_info_score  0.644796"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = HDBSCAN(min_cluster_size=100, min_samples = 15, cluster_selection_epsilon = 0.05, core_dist_n_jobs=-1).fit_predict(umap_train)\n",
    "\n",
    "get_cluster_metrics(labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, K-mean is the best performing algorithm. It outperforms DBSCAN/HDBSCAN and slightly outperforms Agglomerative by a very slim margin. We believe this is caused by the sparse nature of the dataset, which favors K-mean over DBSCAN/HDBSCAN. Moreover, K-mean and Agglomerative have the advantage of knowing the exact number of clusters, while DBSCAN/HDBSCAN doesn't."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
